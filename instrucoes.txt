Para atender às suas solicitações de adicionar efeitos visuais (ondas sonoras) e melhorar a precisão da transcrição (ortografia), precisamos fazer alterações principalmente no arquivo `AudioProcessorService.cs` e um pequeno ajuste no `KaraokeApp.csproj` para suportar modelos de IA mais robustos.

Aqui está o resumo do que foi alterado e por que:

1.  **Melhoria na Transcrição (Correção Ortográfica):** O modelo `base` (usado atualmente) é muito simples e tende a errar a ortografia e pontuação em português. Alterei o código para priorizar o modelo `medium` (médio). **Atenção:** Você precisará baixar o arquivo do modelo `ggml-medium.bin`.
2.  **Efeito Visual (Ondas):** Substituí a geração de vídeo de fundo preto pelo filtro `showwaves` do FFmpeg. Isso criará uma animação de ondas sincronizada com o áudio instrumental.

### 1\. AudioProcessorService.cs (Modificado)

Substitua todo o conteúdo do seu arquivo atual por este.

```csharp
using Whisper.net;
using Whisper.net.Ggml;
using Xabe.FFmpeg;
using System.IO;
using System.Text;
using System.Threading.Tasks;
using Microsoft.Extensions.Configuration;
using System.Collections.Generic;
using System.Linq;
using Microsoft.Extensions.Logging;
using System.Diagnostics;
using System;

public class AudioProcessorService
{
    private readonly string _modelPath;
    private readonly int _videoWidth;
    private readonly int _videoHeight;
    private readonly ILogger<AudioProcessorService> _logger;
    private readonly IConfiguration _configuration;
    private readonly string _vocalRemover;

    public AudioProcessorService(IConfiguration configuration, ILogger<AudioProcessorService> logger)
    {
        _modelPath = configuration["Whisper:ModelPath"] ?? "WhisperModels";
        _videoWidth = int.Parse(configuration["Video:Width"] ?? "1280");
        _videoHeight = int.Parse(configuration["Video:Height"] ?? "720");
        _logger = logger;
        _configuration = configuration;
        _vocalRemover = configuration["Audio:VocalRemover"] ?? "ffmpeg";
    }

    public async Task InitializeAsync()
    {
        await Task.Delay(1);
    }

    public async Task<string> GenerateSrtFromAudioAsync(string audioPath, string language)
    {
        // Converte áudio para WAV temporário para o Whisper
        string wavPath = Path.ChangeExtension(Path.GetTempFileName(), ".wav");
        var command = $"-i \"{audioPath}\" -vn -acodec pcm_s16le -ar 16000 -ac 1 \"{wavPath}\"";
        _logger.LogInformation("FFmpeg command: {command}", command);
        await FFmpeg.Conversions.New().AddParameter(command).Start();

        // ALTERAÇÃO 1: Melhoria da Precisão
        // Tenta usar o modelo Medium (melhor ortografia) antes do Base.
        // O modelo Medium requer mais RAM, mas erra muito menos.
        string modelName = "ggml-medium.bin"; 
        
        // Se quiser especificidade por lingua, pode manter a lógica abaixo, 
        // mas o medium multilingue geral já é excelente.
        if (language == "en") modelName = "ggml-medium-en.bin"; 

        string modelFilePath = Path.Combine(_modelPath, modelName);

        // Fallback para o base se o medium não existir
        if (!File.Exists(modelFilePath))
        {
            _logger.LogWarning("Modelo Medium não encontrado em {path}. Usando fallback para Base.", modelFilePath);
            modelFilePath = Path.Combine(_modelPath, "ggml-base.bin");
        }
        
        if (!File.Exists(modelFilePath))
        {
            throw new FileNotFoundException($"Nenhum modelo Whisper encontrado em {_modelPath}. Baixe o ggml-medium.bin.");
        }

        var segments = new List<Whisper.net.SegmentData>();
        using var whisperFactory = WhisperFactory.FromPath(modelFilePath);
        
        // Configurações para melhorar a pontuação e contexto
        using var processor = whisperFactory.CreateBuilder()
            .WithLanguage(language)
            .WithProbabilities() // Ajuda na precisão interna
            .Build();

        using var fileStream = File.OpenRead(wavPath);
        await foreach (var segment in processor.ProcessAsync(fileStream))
        {
            segments.Add(segment);
        }

        var srtBuilder = new StringBuilder();
        for (int i = 0; i < segments.Count; i++)
        {
            var currentSegment = segments[i];
            var nextSegment = (i + 1 < segments.Count) ? segments[i + 1] : null;

            srtBuilder.AppendLine((i + 1).ToString());
            srtBuilder.AppendLine($"{FormatTime(currentSegment.Start)} --> {FormatTime(currentSegment.End)}");
            srtBuilder.AppendLine(currentSegment.Text.Trim());
            
            // Lógica de mostrar a próxima frase (karaoke style)
            if (nextSegment != null)
            {
                srtBuilder.AppendLine(@"..." + @"{\fs14\c&H808080&}" + nextSegment.Text.Trim() + @"..."); // Diminuí a fonte da próxima frase e mudei pra cinza
            }
            srtBuilder.AppendLine();
        }

        File.Delete(wavPath);
        string srtPath = Path.ChangeExtension(audioPath, ".srt");
        await File.WriteAllTextAsync(srtPath, srtBuilder.ToString());

        return srtPath;
    }

    public async Task<string> RemoveVocalsAsync(string inputAudioPath)
    {
        // (Mantive a lógica original do Demucs/FFmpeg pois estava correta)
        if (_vocalRemover == "demucs")
        {
            var process = new Process
            {
                StartInfo = new ProcessStartInfo
                {
                    FileName = "demucs",
                    Arguments = $"--two-stems=vocals \"{inputAudioPath}\"",
                    RedirectStandardOutput = true,
                    RedirectStandardError = true,
                    UseShellExecute = false,
                    CreateNoWindow = true,
                }
            };
            process.Start();
            string error = await process.StandardError.ReadToEndAsync();
            await process.WaitForExitAsync();

            if (process.ExitCode != 0) throw new Exception($"Demucs failed: {error}");

            var separatedPath = Path.Combine("separated", "htdemucs", Path.GetFileNameWithoutExtension(inputAudioPath));
            var noVocalsPath = Path.Combine(separatedPath, "no_vocals.wav");

            if (!File.Exists(noVocalsPath)) throw new Exception("Demucs output missing.");

            string instrumentalPath = Path.ChangeExtension(inputAudioPath, "_instrumental.mp4");
            var command = $"-i \"{noVocalsPath}\" -vn -c:a aac -ar 44100 \"{instrumentalPath}\"";
            await FFmpeg.Conversions.New().AddParameter(command).Start();

            Directory.Delete(separatedPath, true);
            return instrumentalPath;
        }
        else
        {
            string instrumentalPath = Path.ChangeExtension(inputAudioPath, "_instrumental.mp4");
            var command1 = $"-i \"{inputAudioPath}\" -vn -af pan=stereo|c0=FL-0.5*FC|c1=FR-0.5*FC -c:a aac -ar 44100 \"{instrumentalPath}\"";
            await FFmpeg.Conversions.New().AddParameter(command1).Start();
            return instrumentalPath;
        }
    }

    public async Task<string> GenerateBlackVideoWithAudioAndSubtitlesAsync(string instrumentalAudioPath, string srtPath)
    {
        string outputPath = Path.ChangeExtension(instrumentalAudioPath, ".mp4").Replace("_instrumental", "_karaoke");

        // Tratamento do caminho do SRT para o filtro do FFmpeg (escape de caracteres)
        var srtPathForFilter = srtPath.Replace(@"\", @"\\").Replace(":", @"\:");
        
        // Estilo da legenda
        // PrimaryColour=&H00FFFF (Amarelo/Ciano) - Formato BGR no ASS/SSA (Hex invertido)
        // Outline=1 (Borda preta para legibilidade sobre as ondas)
        string subtitleStyle = "Alignment=2,Fontsize=24,PrimaryColour=&H00FFFF,Outline=1,BackColour=&H80000000,BorderStyle=3";

        // ALTERAÇÃO 2: Efeitos Visuais (Waveform)
        // Usamos filter_complex para gerar vídeo a partir do áudio
        // [0:a]showwaves -> Gera as ondas baseadas no som
        // mode=line -> Tipo de onda
        // colors=cyan -> Cor da onda
        // [v]subtitles -> Aplica a legenda sobre o vídeo de ondas gerado
        
        var filterComplex = $"[0:a]showwaves=s={_videoWidth}x{_videoHeight}:mode=line:colors=cyan:rate=25[waves];[waves]subtitles=filename='{srtPathForFilter}':force_style='{subtitleStyle}'[outv]";

        var command = $"-i \"{instrumentalAudioPath}\" -filter_complex \"{filterComplex}\" -map \"[outv]\" -map 0:a -c:v libx264 -pix_fmt yuv420p -b:v 2M -preset fast \"{outputPath}\"";

        _logger.LogInformation("FFmpeg command (Visual Effects): {command}", command);
        
        await FFmpeg.Conversions.New()
            .AddParameter(command)
            .Start();

        return outputPath;
    }

    private string FormatTime(TimeSpan ts)
    {
        return ts.ToString(@"hh\:mm\:ss\,fff");
    }
}
```

### 2\. KaraokeApp.csproj (Modificado)

Modifiquei apenas a seção `ItemGroup` onde estão os modelos. É **crucial** que você baixe o modelo novo.

```xml
<Project Sdk="Microsoft.NET.Sdk.Web">

  <PropertyGroup>
    <TargetFramework>net7.0</TargetFramework>
    <Nullable>enable</Nullable>
    <ImplicitUsings>enable</ImplicitUsings>
    <AllowUnsafeBlocks>true</AllowUnsafeBlocks>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Whisper.Net" Version="1.5.0" />
    <PackageReference Include="Whisper.Net.Runtime" Version="1.5.0" />
    <PackageReference Include="Xabe.FFmpeg" Version="5.2.4" />
    <PackageReference Include="Serilog.AspNetCore" Version="8.0.1" />
    <PackageReference Include="Serilog.Sinks.File" Version="5.0.0" />
  </ItemGroup>

  <ItemGroup>
    <Content Include="WhisperModels/*.bin">
      <CopyToOutputDirectory>PreserveNewest</CopyToOutputDirectory>
    </Content>
  </ItemGroup>

</Project>
```

### Passo Importante: Baixar o Modelo

Para que a correção ortográfica funcione, você **não pode** usar apenas o modelo `base`. O código agora procura pelo `ggml-medium.bin`.

1.  Vá até o site [HuggingFace - Whisper GGML Models](https://huggingface.co/ggerganov/whisper.cpp/tree/main) ou use o script de download do Whisper.
2.  Baixe o arquivo **`ggml-medium.bin`** (aproximadamente 1.5GB).
3.  Coloque este arquivo dentro da pasta `src/KaraokeApp/WhisperModels/` (junto com o `ggml-base.bin` que você já tem).

### Explicação das Mudanças

1.  **`GenerateSrtFromAudioAsync`**:

      * Mudei a prioridade para carregar `ggml-medium.bin`. Modelos maiores entendem o contexto da frase, diferenciando "assento" de "acento" e pontuando corretamente perguntas e afirmações.
      * Adicionei um tratamento de erro: se ele não achar o modelo Medium, ele avisa no log e tenta usar o Base.

2.  **`GenerateBlackVideoWithAudioAndSubtitlesAsync`**:

      * O comando antigo usava `color=c=black`.
      * O novo comando usa `showwaves`. Ele lê a entrada de áudio e desenha linhas ciano (`colors=cyan`) que pulam conforme a batida da música.
      * Adicionei `pix_fmt yuv420p` para garantir compatibilidade do vídeo com players (como QuickTime ou Windows Media Player) e navegadores.

3.  **Visual das Legendas**:

      * Adicionei `Outline=1` e `BackColour` (caixa semitransparente) nas legendas. Como o fundo agora tem ondas se mexendo, a legenda precisa de uma borda ou fundo para não ficar ilegível quando a onda passar por trás do texto.